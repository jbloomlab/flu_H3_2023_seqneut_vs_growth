{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3a55c8-ed49-44d3-be90-62afd27dcb5f",
   "metadata": {},
   "source": [
    "# Estimate strain growth advantages using MLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15018be3-5558-4a91-84c5-e973a31d7d51",
   "metadata": {},
   "source": [
    "Import modules including [evofr](https://blab.github.io/evofr/) and get variables from `snakemake`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd343a7-5bfe-41c7-99eb-05786c2fed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import re\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import evofr\n",
    "import evofr.plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "_ = alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c740fc-a9a1-4db2-8caf-155b00102d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables from `snakemake`\n",
    "\n",
    "desc = f\"{snakemake.wildcards.protset}_{snakemake.wildcards.mlrfit}\"\n",
    "print(desc)\n",
    "\n",
    "counts_by_date_csv = snakemake.input.counts_by_date\n",
    "\n",
    "chart_html = snakemake.output.chart\n",
    "counts_to_fit_csv = snakemake.output.counts_to_fit\n",
    "growth_advantages_csv = snakemake.output.growth_advantages\n",
    "\n",
    "date_start = snakemake.params.date_start\n",
    "date_end = snakemake.params.date_end\n",
    "assert all(isinstance(d, datetime.date) for d in [date_start, date_end])\n",
    "date_start = pd.Timestamp(date_start)\n",
    "date_end = pd.Timestamp(date_end)\n",
    "assert date_start < date_end\n",
    "\n",
    "min_counts = snakemake.params.min_counts\n",
    "\n",
    "keep_not_in_library = snakemake.params.keep_not_in_library\n",
    "keep_insufficient_counts = snakemake.params.keep_insufficient_counts\n",
    "\n",
    "plot_window_frame_days = snakemake.params.plot_window_frame_days\n",
    "pivot_strain = snakemake.params.pivot_strain\n",
    "mlr_tau = snakemake.params.mlr_tau\n",
    "num_warmup = snakemake.params.num_warmup\n",
    "num_samples = snakemake.params.num_samples\n",
    "hpd_interval = snakemake.params.hpd_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4eb56e-b818-48f8-b932-526cd9d57bff",
   "metadata": {},
   "source": [
    "## Counts for each strain by date\n",
    "\n",
    "Read data.\n",
    "We filter for counts within the specified date range, and then filter for strains that have sufficient counts in that range.\n",
    "At the end of this, strains fall in one of three categories:\n",
    " - a named library strain (eg, *A/Bhutan/0845/2023*)\n",
    " - *strain not in library*: does not match a strain in library\n",
    " - *library strains with insufficient counts*: strains in the library with insufficient counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9efd11-16ff-499e-a9d0-bff53512099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_IN_LIBRARY = \"strain not in library\"\n",
    "INSUFFICIENT_COUNTS = \"library strains insufficient counts\"\n",
    "\n",
    "all_counts_by_date = (\n",
    "    pd.read_csv(counts_by_date_csv, parse_dates=[\"date\"])\n",
    "    .sort_values([\"date\", \"variant\"])\n",
    ")\n",
    "\n",
    "if date_start < all_counts_by_date[\"date\"].min():\n",
    "    raise ValueError(f\"{date_start=} before {all_counts_by_date['date'].min()=}\")\n",
    "if date_end > all_counts_by_date[\"date\"].max():\n",
    "    raise ValueError(f\"{date_start=} after {all_counts_by_date['date'].max()=}\")\n",
    "\n",
    "print(f\"Trimming counts by date to the range {date_start=} to {date_end=}\")\n",
    "all_counts_by_date = all_counts_by_date[\n",
    "    (all_counts_by_date[\"date\"] >= date_start)\n",
    "    & (all_counts_by_date[\"date\"] <= date_end)\n",
    "]\n",
    "\n",
    "assert \"other\" in set(all_counts_by_date[\"variant\"])\n",
    "assert NOT_IN_LIBRARY not in set(all_counts_by_date[\"variant\"])\n",
    "all_counts_by_date[\"variant\"] = all_counts_by_date[\"variant\"].replace(\n",
    "    \"other\", NOT_IN_LIBRARY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac0a07-cb8b-48ff-8237-502de754fc16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:37:24.910749Z",
     "iopub.status.busy": "2024-09-08T03:37:24.910057Z",
     "iopub.status.idle": "2024-09-08T03:37:24.918496Z",
     "shell.execute_reply": "2024-09-08T03:37:24.917076Z",
     "shell.execute_reply.started": "2024-09-08T03:37:24.910684Z"
    }
   },
   "source": [
    "Get total counts for each variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6893b1-3230-4332-8cbe-4708ad3fcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = (\n",
    "    all_counts_by_date\n",
    "    .groupby(\"variant\", as_index=False)\n",
    "    .aggregate(total_sequences=pd.NamedAgg(\"sequences\", \"sum\"))\n",
    "    .assign(sufficient_counts=lambda x: x[\"total_sequences\"] >= min_counts)\n",
    ")\n",
    "\n",
    "total_counts_chart = (\n",
    "    alt.Chart(total_counts)\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"variant\",\n",
    "            sort=alt.SortField(\"total_sequences\", order=\"descending\"),\n",
    "            title=None,\n",
    "        ),\n",
    "        alt.Y(\n",
    "            \"total_sequences\",\n",
    "            scale=alt.Scale(type=\"symlog\", constant=50),\n",
    "            title=\"total sequences\",\n",
    "            axis=alt.Axis(grid=False),\n",
    "        ),\n",
    "        alt.Fill(\n",
    "            \"sufficient_counts\",\n",
    "            scale=alt.Scale(range=[\"gray\", \"white\"], domain=[True, False]),\n",
    "            title=\"sufficient counts?\",\n",
    "            legend=alt.Legend(orient=\"top-right\", offset=3)\n",
    "        ),\n",
    "        tooltip=total_counts.columns.tolist(),\n",
    "    )\n",
    "    .mark_bar(stroke=\"black\")\n",
    "    .properties(\n",
    "        height=150,\n",
    "        width=alt.Step(11),\n",
    "        title=f\"total sequences per strain from {date_start.date()} to {date_end.date()}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "total_counts_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c779ace-81b7-4061-99ed-16336fd4b035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T13:31:27.919795Z",
     "iopub.status.busy": "2024-09-08T13:31:27.919178Z",
     "iopub.status.idle": "2024-09-08T13:31:27.942852Z",
     "shell.execute_reply": "2024-09-08T13:31:27.942020Z",
     "shell.execute_reply.started": "2024-09-08T13:31:27.919751Z"
    }
   },
   "source": [
    "Now filter the counts by date to group all library strains with insufficient counts.\n",
    "Also pad any missing dates in the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1efbb0-0a46-49d9-9213-d7361c7014f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strains_w_insufficient_counts = set(\n",
    "    total_counts\n",
    "    .query(\"(not sufficient_counts) and variant != @NOT_IN_LIBRARY\")\n",
    "    [\"variant\"]\n",
    ")\n",
    "\n",
    "print(f\"Grouping {len(strains_w_insufficient_counts)=} to '{INSUFFICIENT_COUNTS}'\")\n",
    "\n",
    "assert INSUFFICIENT_COUNTS not in set(all_counts_by_date[\"variant\"])\n",
    "\n",
    "# group strains w insufficient counts and pad zero counts on days w no counts\n",
    "filtered_counts_by_date = (\n",
    "    all_counts_by_date\n",
    "    .assign(\n",
    "        variant=lambda x: x[\"variant\"].map(\n",
    "            lambda v: INSUFFICIENT_COUNTS if v in strains_w_insufficient_counts else v\n",
    "        ),\n",
    "        day=lambda x: (x[\"date\"] - date_start).dt.days,\n",
    "    )\n",
    "    .groupby([\"variant\", \"day\"], as_index=False)\n",
    "    .aggregate({\"sequences\": \"sum\"})\n",
    "    .sort_values([\"day\", \"variant\"])\n",
    ")\n",
    "\n",
    "days = filtered_counts_by_date[\"day\"].unique()\n",
    "assert all(days == days.astype(int)), \"dates not all rounded to day\"\n",
    "\n",
    "print(f\"Padding with zero counts any missing days between {date_start} and {date_end}\")\n",
    "filtered_counts_by_date = (\n",
    "    filtered_counts_by_date\n",
    "    .merge(\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                (v, d)\n",
    "                for v in filtered_counts_by_date[\"variant\"].unique()\n",
    "                for d in range(days.min(), days.max() + 1)\n",
    "            ],\n",
    "            columns=[\"variant\", \"day\"],\n",
    "        ),\n",
    "        how=\"outer\",\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    "    .assign(\n",
    "        sequences=lambda x: x[\"sequences\"].fillna(0),\n",
    "        date=lambda x: x[\"day\"].map(lambda d: date_start + pd.Timedelta(days=d)),\n",
    "    )\n",
    "    .drop(columns=\"day\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c1ba3-5271-49bb-9807-2cd5a168bce7",
   "metadata": {},
   "source": [
    "Plot number of strains in each group as a function of date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d94fb-0216-4269-a3d0-6b50f958907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an integer days columns so we can impute missing days\n",
    "grouped_counts_by_date = (\n",
    "    filtered_counts_by_date\n",
    "    .assign(\n",
    "        set_of_strains=lambda x: x[\"variant\"].map(\n",
    "            lambda v: (\n",
    "                \"library strains\"\n",
    "                if v not in {INSUFFICIENT_COUNTS, NOT_IN_LIBRARY}\n",
    "                else v\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    .groupby([\"set_of_strains\", \"date\"], as_index=False)\n",
    "    .aggregate({\"sequences\": \"sum\"})\n",
    ")\n",
    "\n",
    "grouped_counts_by_date_chart = (\n",
    "    alt.Chart(grouped_counts_by_date)\n",
    "    .transform_window(\n",
    "        count=\"mean(sequences)\",\n",
    "        groupby=[\"set_of_strains\"],\n",
    "        frame=[-plot_window_frame_days, plot_window_frame_days],\n",
    "    )\n",
    "    .transform_joinaggregate(total_count=\"sum(count)\", groupby=[\"date\"])\n",
    "    .transform_calculate(fraction=alt.datum.count / alt.datum.total_count)\n",
    "    .transform_fold(\n",
    "        fold=[\"count\", \"fraction\"],\n",
    "        as_=[\"statistic\", \"count_or_fraction\"],\n",
    "    )\n",
    "    .encode(\n",
    "        alt.X(\"date\", title=None, axis=alt.Axis(grid=False, format=\"%b-%Y\", labelAngle=-90)),\n",
    "        alt.Y(\n",
    "            \"count_or_fraction:Q\",\n",
    "            axis=alt.Axis(grid=False),\n",
    "            title=None,\n",
    "            scale=alt.Scale(nice=False)\n",
    "        ),\n",
    "        alt.Fill(\n",
    "            \"set_of_strains\",\n",
    "            title=\"set of strains\",\n",
    "            legend=alt.Legend(orient=\"top\", labelLimit=500, titleOrient=\"left\"),\n",
    "        ),\n",
    "        alt.Column(\n",
    "            \"statistic:N\",\n",
    "            title=None,\n",
    "            header=alt.Header(orient=\"left\", labelFontStyle=\"bold\", labelFontSize=11)\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"set_of_strains\",\n",
    "            \"date\",\n",
    "            \"statistic:N\",\n",
    "            alt.Tooltip(\"count_or_fraction:Q\", format=\".2f\"),\n",
    "        ],\n",
    "    )\n",
    "    .mark_area()\n",
    "    .properties(\n",
    "        width=350,\n",
    "        height=160,\n",
    "        title=alt.TitleParams(\n",
    "            (\n",
    "                \"count or fraction of sequences in each set of strains \"\n",
    "                f\"(rolling mean +/- {plot_window_frame_days} days)\"\n",
    "            ),\n",
    "            anchor=\"middle\",\n",
    "        )\n",
    "    )\n",
    "    .resolve_scale(y=\"independent\")\n",
    ")\n",
    "\n",
    "grouped_counts_by_date_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ade9a9-cd4d-4397-8bb9-cd48ecceed94",
   "metadata": {},
   "source": [
    "Now make per-strain plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daad257-8839-48f3-b510-e59ed126447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_selection = alt.selection_point(\n",
    "    fields=[\"statistic\"],\n",
    "    bind=alt.binding_radio(\n",
    "        options=[\"count\", \"fraction\"],\n",
    "        name=\"show count or fraction on y-axis?\",\n",
    "    ),\n",
    "    value=\"fraction\",\n",
    ")\n",
    "\n",
    "include_not_in_library = alt.param(\n",
    "    bind=alt.binding_radio(\n",
    "        options=[True, False],\n",
    "        name=f\"include {NOT_IN_LIBRARY}?\",\n",
    "    ),\n",
    "    value=keep_not_in_library,\n",
    ")\n",
    "\n",
    "include_insufficient_counts = alt.param(\n",
    "    bind=alt.binding_radio(\n",
    "        options=[True, False],\n",
    "        name=f\"include {INSUFFICIENT_COUNTS}?\",\n",
    "    ),\n",
    "    value=keep_insufficient_counts,\n",
    ") \n",
    "\n",
    "counts_by_date_chart = (\n",
    "    alt.Chart(filtered_counts_by_date)\n",
    "    .add_params(statistic_selection, include_not_in_library, include_insufficient_counts)\n",
    "    .transform_filter((alt.datum[\"variant\"] != NOT_IN_LIBRARY) | include_not_in_library)\n",
    "    .transform_filter((alt.datum[\"variant\"] != INSUFFICIENT_COUNTS) | include_insufficient_counts)\n",
    "    .transform_window(\n",
    "        count=\"mean(sequences)\",\n",
    "        groupby=[\"variant\"],\n",
    "        frame=[-plot_window_frame_days, plot_window_frame_days],\n",
    "    )\n",
    "    .transform_joinaggregate(total_count=\"sum(count)\", groupby=[\"date\"])\n",
    "    .transform_calculate(fraction=alt.datum.count / alt.datum.total_count)\n",
    "    .transform_fold(\n",
    "        fold=[\"count\", \"fraction\"],\n",
    "        as_=[\"statistic\", \"count_or_fraction\"],\n",
    "    )\n",
    "    .transform_filter(statistic_selection)\n",
    "    .encode(\n",
    "        alt.X(\"date\", title=None, axis=alt.Axis(grid=False, format=\"%b-%Y\", labelAngle=-90)),\n",
    "        alt.Y(\n",
    "            \"count_or_fraction:Q\",\n",
    "            axis=alt.Axis(grid=False),\n",
    "            title=\"sequences\",\n",
    "            scale=alt.Scale(nice=False)\n",
    "        ),\n",
    "        alt.Facet(\n",
    "            \"variant\",\n",
    "            title=None,\n",
    "            header=alt.Header(labelFontSize=9, labelPadding=0),\n",
    "            columns=5,\n",
    "            spacing=5,\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"variant\",\n",
    "            \"date\",\n",
    "            \"statistic:N\",\n",
    "            alt.Tooltip(\"count_or_fraction:Q\", format=\".2f\"),\n",
    "        ],\n",
    "    )\n",
    "    .mark_area(stroke=\"black\", fill=\"gray\")\n",
    "    .properties(\n",
    "        width=160,\n",
    "        height=70,\n",
    "        title=alt.TitleParams(\n",
    "            (\n",
    "                \"count or fraction of sequences for each strain \"\n",
    "                f\"(rolling mean +/- {plot_window_frame_days} days)\"\n",
    "            ),\n",
    "            anchor=\"middle\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "counts_by_date_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0742684-7c90-4f2d-9e18-fbbc7064c608",
   "metadata": {},
   "source": [
    "## Fit MLR models\n",
    "\n",
    "Get the counts to fit and write to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823bb8b8-449d-477d-8a98-79c704497446",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_to_fit = filtered_counts_by_date\n",
    "\n",
    "for (keep, strainset) in [\n",
    "    (keep_not_in_library, NOT_IN_LIBRARY),\n",
    "    (keep_insufficient_counts, INSUFFICIENT_COUNTS),\n",
    "]:\n",
    "    if not keep:\n",
    "        print(f\"Dropping {strainset}\")\n",
    "        counts_to_fit = counts_to_fit[counts_to_fit[\"variant\"] != strainset]\n",
    "\n",
    "strains_to_fit = sorted(counts_to_fit[\"variant\"].unique())\n",
    "dates_to_fit = counts_to_fit[\"date\"].unique()\n",
    "\n",
    "print(f\"Fitting counts for {len(strains_to_fit)=} to {len(dates_to_fit)=}\")\n",
    "assert len(counts_to_fit) == len(strains_to_fit) * len(dates_to_fit)\n",
    "\n",
    "print(f\"Writing the counts to fit to {counts_to_fit_csv}\")\n",
    "counts_to_fit.to_csv(counts_to_fit_csv, index=False, float_format=\"%.2f\")\n",
    "\n",
    "if pivot_strain not in strains_to_fit:\n",
    "    raise ValueError(f\"{pivot_strain=} not in {strains_to_fit=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1aa24-88e0-4670-a2f8-9a3d3eaaafa9",
   "metadata": {},
   "source": [
    "Now set up and fit MLR model following [here](https://blab.github.io/evofr/notebooks/example_mlr.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b67ea-3531-44cd-8461-1e0207bbcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_frequencies = evofr.VariantFrequencies(\n",
    "    counts_to_fit, pivot=pivot_strain, var_names=strains_to_fit\n",
    ")\n",
    "\n",
    "mlr = evofr.MultinomialLogisticRegression(tau=mlr_tau)\n",
    "\n",
    "inference_method = evofr.InferNUTS(num_samples=num_samples, num_warmup=num_warmup)\n",
    "\n",
    "posterior = inference_method.fit(mlr, variant_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84748c6-4efe-4c40-a024-7d07977591eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T19:48:50.709459Z",
     "iopub.status.busy": "2024-09-10T19:48:50.708705Z",
     "iopub.status.idle": "2024-09-10T19:48:50.731106Z",
     "shell.execute_reply": "2024-09-10T19:48:50.730312Z",
     "shell.execute_reply.started": "2024-09-10T19:48:50.709394Z"
    }
   },
   "source": [
    "Get the frequencies and growth advantages and their intervals (highest posterior density):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227fbb3e-93e7-4d69-8c64-4d05830d6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = posterior.samples[\"freq\"]\n",
    "\n",
    "assert freqs.shape[0] == num_samples\n",
    "freqs.shape[1] == counts_to_fit[\"date\"].nunique()\n",
    "freqs.shape[2] == len(strains_to_fit)\n",
    "\n",
    "\n",
    "def hpd(data, hpd_level):\n",
    "    \"\"\"Calculate the HPD of a 1D array for a given level.\"\"\"\n",
    "    data = numpy.sort(data, axis=0)  # Sort the data\n",
    "    n = len(data)\n",
    "    interval_index = int(numpy.floor(hpd_level * n))\n",
    "    \n",
    "    # Find the range of values that gives the narrowest HPD interval\n",
    "    intervals = data[interval_index:] - data[:n - interval_index]\n",
    "    min_idx = numpy.argmin(intervals)\n",
    "    hpd_min = data[min_idx]\n",
    "    hpd_max = data[min_idx + interval_index]\n",
    "    return hpd_min, hpd_max\n",
    "\n",
    "\n",
    "def hpd_over_axis(data, hpd_level, axis):\n",
    "    \"\"\"Calculate the HPD over a specific axis for a NumPy array.\"\"\"\n",
    "    # Move the target axis to the last dimension for easy iteration\n",
    "    data_swapped = numpy.moveaxis(data, axis, -1)\n",
    "    \n",
    "    # Apply the HPD calculation over the last axis\n",
    "    hpd_min = numpy.apply_along_axis(lambda x: hpd(x, hpd_level=hpd_level)[0], -1, data_swapped)\n",
    "    hpd_max = numpy.apply_along_axis(lambda x: hpd(x, hpd_level=hpd_level)[1], -1, data_swapped)\n",
    "    \n",
    "    return hpd_min, hpd_max\n",
    "\n",
    "freqs_median = numpy.median(freqs, axis=0)\n",
    "freqs_hpd_min, freqs_hpd_max = hpd_over_axis(freqs, hpd_interval / 100, axis=0)\n",
    "dates = posterior.data.dates\n",
    "\n",
    "assert freqs_median.shape == freqs_hpd_min.shape == freqs_hpd_max.shape\n",
    "assert freqs_median.shape == (len(dates), len(strains_to_fit))\n",
    "\n",
    "freqs_df = (\n",
    "    pd.DataFrame(freqs_median, columns=strains_to_fit, index=dates)\n",
    "    .reset_index(names=\"date\")\n",
    "    .melt(id_vars=\"date\", var_name=\"strain\", value_name=\"freq_median\")\n",
    "    .merge(\n",
    "        (\n",
    "            pd.DataFrame(freqs_hpd_min, columns=strains_to_fit, index=dates)\n",
    "            .reset_index(names=\"date\")\n",
    "            .melt(id_vars=\"date\", var_name=\"strain\", value_name=\"freq_hpd_min\")\n",
    "        ),\n",
    "        on=[\"strain\", \"date\"],\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    "    .merge(\n",
    "        (\n",
    "            pd.DataFrame(freqs_hpd_max, columns=strains_to_fit, index=dates)\n",
    "            .reset_index(names=\"date\")\n",
    "            .melt(id_vars=\"date\", var_name=\"strain\", value_name=\"freq_hpd_max\")\n",
    "        ),\n",
    "        on=[\"strain\", \"date\"],\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    ")\n",
    "\n",
    "assert len(freqs_df) == len(dates) * len(strains_to_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5970c-36d6-442b-b8dc-2fbd796157b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas = posterior.samples[\"ga\"]\n",
    "assert gas.shape == (num_samples, len(strains_to_fit) - 1)\n",
    "\n",
    "gas_median = numpy.median(gas, axis=0)\n",
    "gas_hpd_min, gas_hpd_max = hpd_over_axis(gas, hpd_interval / 100, axis=0)\n",
    "\n",
    "assert gas_median.shape == gas_hpd_min.shape == gas_hpd_max.shape\n",
    "assert gas_median.shape == (len(strains_to_fit) - 1,)\n",
    "\n",
    "nonpivot_strains = [s for s in strains_to_fit if s != pivot_strain]\n",
    "assert len(nonpivot_strains) == len(strains_to_fit) - 1\n",
    "\n",
    "gas_df = pd.DataFrame(\n",
    "    {\n",
    "        \"growth_advantage_median\": list(gas_median) + [1],\n",
    "        \"growth_advantage_hpd_min\": list(gas_hpd_min) + [1],\n",
    "        \"growth_advantage_hpd_max\": list(gas_hpd_max) + [1],\n",
    "    },\n",
    "    index=nonpivot_strains + [pivot_strain],\n",
    ").reset_index(names=\"strain\")\n",
    "\n",
    "assert len(gas_df) == len(strains_to_fit)\n",
    "\n",
    "print(f\"Writing the growth advantages to {growth_advantages_csv}\")\n",
    "(\n",
    "    gas_df\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"growth_advantage_mean\": \"growth_advantage\",\n",
    "            \"growth_advantange_hpd_min\": f\"growth_advantage_hpd{hpd_interval}_min\",\n",
    "            \"growth_advantange_hpd_max\": f\"growth_advantage_hpd{hpd_interval}_max\",\n",
    "        }\n",
    "    )\n",
    "    .to_csv(growth_advantages_csv, index=False, float_format=\"%.2f\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b417d-c069-4af9-b742-19943b551e42",
   "metadata": {},
   "source": [
    "Plot the frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a77e6-ec4f-41cd-b754-8936ef570d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get a data frame to plot, including adding the rolling average of the actual\n",
    "# sequence fractions\n",
    "\n",
    "windowed_counts_to_fit = (\n",
    "    counts_to_fit\n",
    "    .rename(columns={\"variant\": \"strain\"})\n",
    "    .sort_values(\"date\")\n",
    "    .assign(\n",
    "        frac_sequences=lambda x: x[\"sequences\"] / x.groupby(\"date\")[\"sequences\"].transform(\"sum\")\n",
    "    )\n",
    "    [[\"strain\", \"date\", \"frac_sequences\"]]\n",
    ")\n",
    "\n",
    "windowed_counts_to_fit[\"frac_sequences\"] = (\n",
    "    windowed_counts_to_fit\n",
    "    .groupby(\"strain\")\n",
    "    [\"frac_sequences\"]\n",
    "    .transform(\n",
    "        lambda s: s.rolling(\n",
    "            window=plot_window_frame_days * 2 + 1,\n",
    "            min_periods=1,\n",
    "            center=True,\n",
    "        ).mean()\n",
    "    )\n",
    ")\n",
    "\n",
    "assert len(freqs_df) == len(windowed_counts_to_fit)\n",
    "\n",
    "plot_freqs_df = (\n",
    "    freqs_df\n",
    "    .merge(\n",
    "        (\n",
    "            gas_df\n",
    "            .assign(\n",
    "                growth_advantage=lambda x: x.apply(\n",
    "                    lambda r: f\"{r['growth_advantage_median']:.2f} [{r['growth_advantage_hpd_min']:.2f} - {r['growth_advantage_hpd_max']:.2f}]\",\n",
    "                    axis=1,\n",
    "                )\n",
    "            )\n",
    "            [[\"strain\", \"growth_advantage\"]]\n",
    "        ),\n",
    "        on=\"strain\",\n",
    "        validate=\"many_to_one\",\n",
    "    )\n",
    "    .merge(windowed_counts_to_fit, on=[\"strain\", \"date\"], validate=\"one_to_one\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45198a12-be4c-491c-8461-e48cf216eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq_sorted_strains = (\n",
    "    plot_freqs_df.sort_values(\"freq_median\", ascending=False)[\"strain\"].unique()\n",
    ")\n",
    "\n",
    "strain_selection = alt.selection_point(\n",
    "    fields=[\"strain\"],\n",
    "    bind=alt.binding_select(\n",
    "        options=[None] + strains_to_fit,\n",
    "        labels=[\"all\"] + strains_to_fit,\n",
    "        name=\"strain(s) to show for MLR fit:\",\n",
    "    )\n",
    ")\n",
    "\n",
    "freqs_chart_base = (\n",
    "    alt.Chart(plot_freqs_df)\n",
    "    .transform_filter(strain_selection)\n",
    "    .encode(\n",
    "        alt.X(\n",
    "            \"date\",\n",
    "            title=None,\n",
    "            axis=alt.Axis(grid=False, format=\"%b-%Y\", labelAngle=-90),\n",
    "        ),\n",
    "        alt.Color(\n",
    "            \"strain\",\n",
    "            scale=alt.Scale(domain=max_freq_sorted_strains, scheme=\"category20\"),\n",
    "            legend=alt.Legend(\n",
    "                labelLimit=500,\n",
    "                columns=int(math.ceil(plot_freqs_df[\"strain\"].nunique() / 12)),\n",
    "            ),\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"strain\",\n",
    "            \"growth_advantage\",\n",
    "            \"date\",\n",
    "            alt.Tooltip(\"freq_median\", format=\".2f\", title=\"predicted frequency\"),\n",
    "            alt.Tooltip(\n",
    "                \"frac_sequences\",\n",
    "                format=\".2f\",\n",
    "                title=f\"actual frequency (+/-{plot_window_frame_days} days)\",\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    .properties(\n",
    "        width=450,\n",
    "        height=200,\n",
    "        title=alt.TitleParams(\n",
    "            \"MLR fits and actual frequencies\",\n",
    "            subtitle=f\"actual frequencies plotted as rolling mean +/- {plot_window_frame_days} days\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "freqs_chart_median = (\n",
    "    freqs_chart_base\n",
    "    .add_params(strain_selection)\n",
    "    .encode(alt.Y(\"freq_median\", title=\"strain frequency\", axis=alt.Axis(grid=False)))\n",
    "    .mark_line(opacity=1, strokeWidth=2)\n",
    ")\n",
    "\n",
    "freqs_chart_hpd = (\n",
    "    freqs_chart_base\n",
    "    .encode(\n",
    "        alt.Y(\"freq_hpd_min\"),\n",
    "        alt.Y2(\"freq_hpd_max\"),\n",
    "    )\n",
    "    .mark_area(opacity=0.2)\n",
    ")\n",
    "\n",
    "freqs_chart_points = (\n",
    "    freqs_chart_base\n",
    "    .encode(alt.Y(\"frac_sequences\"))\n",
    "    .mark_circle(size=8, opacity=0.7)\n",
    ")\n",
    "\n",
    "freqs_chart = freqs_chart_median + freqs_chart_hpd + freqs_chart_points\n",
    "\n",
    "freqs_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb359a-2ad4-448e-b489-cb3cd83cb9ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-10T19:56:37.506280Z",
     "iopub.status.busy": "2024-09-10T19:56:37.505490Z",
     "iopub.status.idle": "2024-09-10T19:56:37.515021Z",
     "shell.execute_reply": "2024-09-10T19:56:37.513386Z",
     "shell.execute_reply.started": "2024-09-10T19:56:37.506213Z"
    }
   },
   "source": [
    "Plot the growth advantages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16459f-f244-41f0-ac5e-7b3ba687d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_ytitle = [\"growth advantage relative to\", pivot_strain]\n",
    "\n",
    "ga_points = (\n",
    "    alt.Chart(gas_df)\n",
    "    .encode(\n",
    "        alt.X(\"strain\", title=None),\n",
    "        alt.Y(\n",
    "            \"growth_advantage_median\",\n",
    "            title=ga_ytitle,\n",
    "            scale=alt.Scale(zero=False, nice=False, padding=10),\n",
    "            axis=alt.Axis(grid=False)\n",
    "        ),\n",
    "        tooltip=[\n",
    "            \"strain\",\n",
    "            alt.Tooltip(\"growth_advantage_median\", format=\".2f\", title=\"growth advantage\"),\n",
    "            alt.Tooltip(\"growth_advantage_hpd_min\", format=\".2f\", title=f\"lower HPD{hpd_interval}%\"),\n",
    "            alt.Tooltip(\"growth_advantage_hpd_max\", format=\".2f\", title=f\"upper HPD{hpd_interval}%\"),\n",
    "        ],\n",
    "    )\n",
    "    .mark_circle(color=\"black\", size=75, opacity=1)\n",
    "    .properties(\n",
    "        height=175,\n",
    "        width=alt.Step(18),\n",
    "        title=f\"estimated strain growth advantages and HPD{hpd_interval}%\",\n",
    "    )\n",
    ")\n",
    "\n",
    "ga_hpd = (\n",
    "    alt.Chart(gas_df)\n",
    "    .encode(\n",
    "        alt.X(\"strain\"),\n",
    "        alt.Y(\"growth_advantage_hpd_min\", title=ga_ytitle),\n",
    "        alt.Y2(\"growth_advantage_hpd_max\"),\n",
    "    )\n",
    "    .mark_errorbar(thickness=2)\n",
    ")\n",
    "\n",
    "ga_chart = ga_hpd + ga_points\n",
    "\n",
    "ga_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db88362-e75e-4421-af7d-0e5117e44665",
   "metadata": {},
   "source": [
    "## Save merged chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da24c65-c2a0-4c05-bf7b-5f3307e1573d",
   "metadata": {},
   "source": [
    "Make a merged chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b63a4-ecdd-4771-88f4-15519f175fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart = (\n",
    "    alt.vconcat(\n",
    "        total_counts_chart,\n",
    "        grouped_counts_by_date_chart,\n",
    "        counts_by_date_chart,\n",
    "        freqs_chart,\n",
    "        ga_chart,\n",
    "        spacing=35,\n",
    "    )\n",
    "    .resolve_scale(fill=\"independent\", color=\"independent\")\n",
    "    .properties(\n",
    "        title=alt.TitleParams(\n",
    "            f\"sequence counts and MLR fits for {desc}\",\n",
    "            anchor=\"middle\",\n",
    "            fontSize=15,\n",
    "            dy=-20,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Saving merged chart to {chart_html}\")\n",
    "chart.save(chart_html)\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd4017-02a3-476e-aa45-6872f324ce25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
